import{_ as a,c as l,a as s,o as r}from"./app-DCYTdW2o.js";const t={};function i(e,n){return r(),l("div",null,[...n[0]||(n[0]=[s('<h2 id="具身智能" tabindex="-1"><a class="header-anchor" href="#具身智能"><span>具身智能</span></a></h2><h3 id="什么是具身智能-embodied-ai" tabindex="-1"><a class="header-anchor" href="#什么是具身智能-embodied-ai"><span>什么是具身智能（Embodied AI）</span></a></h3><p>具身智能是指研究能够<strong>感知</strong>、<strong>推理</strong>、<strong>行动</strong>并与物理世界交互的智能体。</p><ul><li><p><strong>感知</strong> 通过传感器接收外部信息，如视觉、声音、语言等。</p></li><li><p><strong>推理</strong> 结合感知信息与人类指令，进行任务推理。</p></li><li><p><strong>行动</strong> 在物理世界中移动或与物体交互（如抓取）。</p></li><li><p><strong>学习机制</strong> 必须通过身体（body）与环境的交互实现学习和理解。</p></li></ul><p>区别于传统AI：</p><ul><li>传统AI侧重符号推理（symbolic reasoning）或数据驱动模式识别。</li><li>具身智能强调与真实世界的动态交互。</li></ul><h3 id="为什么需要具身智能" tabindex="-1"><a class="header-anchor" href="#为什么需要具身智能"><span>为什么需要具身智能</span></a></h3><ul><li><p><strong>真实世界的复杂性</strong> 真实环境涉及物理常识、碰撞、温度变化、光照变化等复杂因素。</p></li><li><p><strong>通往通用人工智能（AGI）的关键一步</strong> 具身智能整合了计算机视觉、自然语言处理、机器人控制等多个AI方向，被视为实现AGI的重要路径。</p></li><li><p><strong>广泛的实际应用场景</strong> 包括机器人技术、智能家居、虚拟助手、灾难救援等。</p></li><li><p><strong>新的学习范式</strong></p><p>需结合监督学习、无监督学习与强化学习。</p><ul><li>初始阶段使用监督学习进行模型初始化。</li><li>后期通过强化学习与环境交互持续优化模型。</li></ul></li></ul><h3 id="vln和具身智能的关系" tabindex="-1"><a class="header-anchor" href="#vln和具身智能的关系"><span>VLN和具身智能的关系</span></a></h3><ul><li>VLN是具身智能的一个子领域。</li><li>类比人体结构： <ul><li>上半身对应操作任务（manipulation），如机械臂抓取。</li><li>下半身对应导航任务，即在空间中移动。</li></ul></li><li>VLN占据具身智能中“下半身”的核心地位。</li></ul><h2 id="vln基础概念" tabindex="-1"><a class="header-anchor" href="#vln基础概念"><span>VLN基础概念</span></a></h2><h3 id="v-计算机视觉" tabindex="-1"><a class="header-anchor" href="#v-计算机视觉"><span>V（计算机视觉）</span></a></h3><p>集成了<strong>分类</strong>，<strong>检测</strong>和<strong>分割</strong>的能力。</p><ul><li><p><strong>图像识别</strong></p><p>判断当前所处环境类型，如厨房、卧室等，提供全局语境。</p></li><li><p><strong>目标检测</strong></p><p>解决“我周围有什么物体”这一问题，要求同时识别物体类别并定位其位置</p></li><li><p><strong>语义分割</strong></p><p>要求像素级别的标注，不仅识别物体，还需明确其形状和边界</p></li></ul><h3 id="l-语言处理" tabindex="-1"><a class="header-anchor" href="#l-语言处理"><span>L（语言处理）</span></a></h3><ul><li><p><strong>词嵌入</strong></p><p>将离散的词语符号映射为连续的、低维稠密向量，表达语义。词嵌入作为语言理解的起点，为编码完整且富含上下文的导航指令提供输入。</p></li><li><p><strong>序列模型（RNN到Transformer）</strong></p><ul><li><p>RNN（早期方法）</p><p>使用带有memory cell的循环结构处理序列信息，有效捕捉上下文关联。</p></li><li><p>Transformer</p><p>以自注意力为核心，融合语言、视觉及历史状态信息。将所有模态的信息整合进统一骨干网络进行处理。</p></li></ul></li></ul><h3 id="vln架构" tabindex="-1"><a class="header-anchor" href="#vln架构"><span>VLN架构</span></a></h3>',17)])])}const p=a(t,[["render",i]]),h=JSON.parse('{"path":"/notes/VLN/hj0mm27u/","title":"VLN","lang":"zh-CN","frontmatter":{"title":"VLN","createTime":"2025/12/27 14:44:18","permalink":"/notes/VLN/hj0mm27u/"},"readingTime":{"minutes":2.32,"words":696},"git":{"createdTime":1766823909000,"updatedTime":1766823909000,"contributors":[{"name":"salt235","username":"salt235","email":"734489881@qq.com","commits":1,"avatar":"https://avatars.githubusercontent.com/salt235?v=4","url":"https://github.com/salt235"}]},"filePathRelative":"notes/VLN/概念/VLN.md","headers":[]}');export{p as comp,h as data};
